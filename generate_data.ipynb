{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, Embedding, Dense, GRU\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_corpus(corpus, num_words=-1):\n",
    "    if num_words > -1:\n",
    "        tokenizer = Tokenizer(num_words=num_words)\n",
    "    else:\n",
    "        tokenizer = Tokenizer()\n",
    "        tokenizer.fit_on_texts(corpus)\n",
    "        \n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = './data/robert_frost.txt'\n",
    "data_file = open(DATA_PATH, \"r\").readlines()\n",
    "\n",
    "data_file = [line.split() for line in data_file]\n",
    "\n",
    "dataset = []\n",
    "for line in data_file:\n",
    "    temp = \"\"\n",
    "    for w in line:\n",
    "        w = w.lower()\n",
    "        w.replace('[{0}]'.format(string.punctuation), '')\n",
    "        temp = temp + \" \" + w\n",
    "        \n",
    "    dataset.append(temp)\n",
    "        \n",
    "tokenizer = tokenize_corpus(dataset)\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "index_to_word = {}\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    index_to_word[index] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = []\n",
    "for line in dataset:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        sequences.append(n_gram_sequence)\n",
    "\n",
    "# Pad sequences for equal input length \n",
    "max_sequence_len = max([len(seq) for seq in sequences])\n",
    "sequences = np.array(pad_sequences(sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "\n",
    "# Split sequences between the \"input\" sequence and \"output\" predicted word\n",
    "input_sequences, labels = sequences[:,:-1], sequences[:,-1]\n",
    "\n",
    "one_hot_labels = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        Embedding(total_words, embedding_dim,  input_length=max_sequence_len-1),\n",
    "        GRU(rnn_units),\n",
    "        Dense(total_words, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 57\n",
    "embedding_dim = 256\n",
    "rnn_units = 1024\n",
    "\n",
    "model = build_model(embedding_dim,\n",
    "                    rnn_units,\n",
    "                    batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 40\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9519 samples\n",
      "Epoch 1/40\n",
      "9519/9519 [==============================] - 7s 729us/sample - loss: 6.6631 - acc: 0.0486\n",
      "Epoch 2/40\n",
      "9519/9519 [==============================] - 5s 479us/sample - loss: 5.9028 - acc: 0.0766\n",
      "Epoch 3/40\n",
      "9519/9519 [==============================] - 5s 481us/sample - loss: 5.2758 - acc: 0.1092\n",
      "Epoch 4/40\n",
      "9519/9519 [==============================] - 5s 479us/sample - loss: 4.4314 - acc: 0.1557s - loss: 4.4307 - acc: 0.\n",
      "Epoch 5/40\n",
      "9519/9519 [==============================] - 5s 478us/sample - loss: 3.2367 - acc: 0.2890\n",
      "Epoch 6/40\n",
      "9519/9519 [==============================] - 5s 478us/sample - loss: 1.9857 - acc: 0.5492\n",
      "Epoch 7/40\n",
      "9519/9519 [==============================] - 5s 478us/sample - loss: 1.2157 - acc: 0.7315s - loss: 1.1631  - ETA: 1s - loss: 1.1 - ETA: 0s - loss: 1.2151 - acc: 0.7\n",
      "Epoch 8/40\n",
      "9519/9519 [==============================] - 5s 478us/sample - loss: 0.8728 - acc: 0.8116\n",
      "Epoch 9/40\n",
      "9519/9519 [==============================] - 5s 477us/sample - loss: 0.7407 - acc: 0.8344\n",
      "Epoch 10/40\n",
      "9519/9519 [==============================] - 5s 478us/sample - loss: 0.6731 - acc: 0.8452\n",
      "Epoch 11/40\n",
      "9519/9519 [==============================] - 5s 477us/sample - loss: 0.6480 - acc: 0.8465\n",
      "Epoch 12/40\n",
      "9519/9519 [==============================] - 5s 477us/sample - loss: 0.6273 - acc: 0.8486\n",
      "Epoch 13/40\n",
      "9519/9519 [==============================] - 5s 477us/sample - loss: 0.6065 - acc: 0.8521\n",
      "Epoch 14/40\n",
      "9519/9519 [==============================] - 5s 480us/sample - loss: 0.6009 - acc: 0.8536s -  - ETA: 1s \n",
      "Epoch 15/40\n",
      "9519/9519 [==============================] - 5s 477us/sample - loss: 0.5896 - acc: 0.8542\n",
      "Epoch 16/40\n",
      "9519/9519 [==============================] - 5s 476us/sample - loss: 0.5859 - acc: 0.8537\n",
      "Epoch 17/40\n",
      "9519/9519 [==============================] - 5s 477us/sample - loss: 0.5803 - acc: 0.8528\n",
      "Epoch 18/40\n",
      "9519/9519 [==============================] - 5s 479us/sample - loss: 0.5740 - acc: 0.8536s - loss: 0.55\n",
      "Epoch 19/40\n",
      "9519/9519 [==============================] - 5s 482us/sample - loss: 0.5690 - acc: 0.8543\n",
      "Epoch 20/40\n",
      "9519/9519 [==============================] - 5s 479us/sample - loss: 0.5641 - acc: 0.8542\n",
      "Epoch 21/40\n",
      "9519/9519 [==============================] - 5s 478us/sample - loss: 0.5745 - acc: 0.8506s - loss: 0.5639 - acc: \n",
      "Epoch 22/40\n",
      "9519/9519 [==============================] - 5s 477us/sample - loss: 0.8652 - acc: 0.7745\n",
      "Epoch 23/40\n",
      "9519/9519 [==============================] - 5s 478us/sample - loss: 0.6795 - acc: 0.8213\n",
      "Epoch 24/40\n",
      "9519/9519 [==============================] - 5s 479us/sample - loss: 0.5670 - acc: 0.8500s - loss: 0.\n",
      "Epoch 25/40\n",
      "9519/9519 [==============================] - 5s 477us/sample - loss: 0.5425 - acc: 0.8561\n",
      "Epoch 26/40\n",
      "9519/9519 [==============================] - 5s 478us/sample - loss: 0.5392 - acc: 0.8546\n",
      "Epoch 27/40\n",
      "9519/9519 [==============================] - 5s 479us/sample - loss: 0.5398 - acc: 0.8530s - loss: 0.5392 - acc: 0.85\n",
      "Epoch 28/40\n",
      "9519/9519 [==============================] - 5s 482us/sample - loss: 0.5311 - acc: 0.8561s - loss: 0.50\n",
      "Epoch 29/40\n",
      "9519/9519 [==============================] - 5s 479us/sample - loss: 0.5309 - acc: 0.8557\n",
      "Epoch 30/40\n",
      "9519/9519 [==============================] - 5s 478us/sample - loss: 0.5325 - acc: 0.8556\n",
      "Epoch 31/40\n",
      "9519/9519 [==============================] - 5s 479us/sample - loss: 0.5303 - acc: 0.8542\n",
      "Epoch 32/40\n",
      "9519/9519 [==============================] - 5s 480us/sample - loss: 0.5299 - acc: 0.8540\n",
      "Epoch 33/40\n",
      "9519/9519 [==============================] - 5s 480us/sample - loss: 0.5285 - acc: 0.8524\n",
      "Epoch 34/40\n",
      "9519/9519 [==============================] - 5s 478us/sample - loss: 0.5237 - acc: 0.8546\n",
      "Epoch 35/40\n",
      "9519/9519 [==============================] - 5s 478us/sample - loss: 0.5240 - acc: 0.8541\n",
      "Epoch 36/40\n",
      "9519/9519 [==============================] - 5s 482us/sample - loss: 0.5219 - acc: 0.8558\n",
      "Epoch 37/40\n",
      "9519/9519 [==============================] - 5s 481us/sample - loss: 0.5162 - acc: 0.8558\n",
      "Epoch 38/40\n",
      "9519/9519 [==============================] - 5s 480us/sample - loss: 0.5169 - acc: 0.8556\n",
      "Epoch 39/40\n",
      "9519/9519 [==============================] - 5s 479us/sample - loss: 0.5186 - acc: 0.8532\n",
      "Epoch 40/40\n",
      "9519/9519 [==============================] - 5s 479us/sample - loss: 0.5309 - acc: 0.8520s - loss: 0.48\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(input_sequences, one_hot_labels, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(embedding_dim, rnn_units, batch_size=1)\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(model, seed_text):\n",
    "    output_len = 20000\n",
    "    for _ in range(output_len):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "        probabilites = model.predict(token_list)\n",
    "        predicted_idx = np.random.choice(total_words, 1, p=probabilites[0])[0]\n",
    "#         predicted_idx = tf.random.categorical(probabilities, num_samples=1)[-1, 0].numpy()\n",
    "        output_word = index_to_word[predicted_idx]\n",
    "        seed_text += \" \" + output_word\n",
    "        \n",
    "    return seed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = './outputs/generated_output_{0}.txt'\n",
    "START_WORDS = [\"the road\", \"my life\", \"the book\"]\n",
    "for i, word in enumerate(START_WORDS):\n",
    "    output_file = open(OUTPUT_PATH.format(i), 'w+')\n",
    "    output_file.write(generate_data(model, word))\n",
    "    output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the road there if you'll let a guide direct you sometimes he liked best right ' he said 'i know ' he said 'it makes me in the cellar house spring as fast ' it said to let them look like me ' he said ' i can't decently refuse you '\n"
     ]
    }
   ],
   "source": [
    "# testing model generated text\n",
    "\n",
    "seed_text = \"the road\"\n",
    "next_words = 50\n",
    "\n",
    "line\n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    probabilities = model.predict(token_list)\n",
    "#     choose_one = random.randint(0, 1)\n",
    "#     if (choose_one == 0):\n",
    "    predicted_idx = np.random.choice(total_words, 1, p=probabilities[0])[0]\n",
    "#     else:\n",
    "#     predicted_idx = tf.random.categorical(probabilities, num_samples=1)[-1, 0].numpy()\n",
    "    output_word = index_to_word[predicted_idx]\n",
    "    seed_text += \" \" + output_word\n",
    "    \n",
    "print(seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
